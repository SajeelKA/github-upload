{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"EE8204LoadingAndRunning.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"1aIx8apZMnwX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":80},"outputId":"01366b2f-50b5-4521-e940-089fcb85f109","executionInfo":{"status":"ok","timestamp":1577212636053,"user_tz":300,"elapsed":2286,"user":{"displayName":"Sajeel Aziz","photoUrl":"","userId":"15109235724799805866"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import pandas as pd\n","from tensorflow import keras\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from keras.utils import np_utils # need pip install\n","from random import randrange\n","from IPython.display import YouTubeVideo\n","\n","from keras.models import Model\n","from keras.layers.normalization import BatchNormalization\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.core import Activation\n","from keras.layers.core import Dropout\n","from keras.layers.core import Lambda\n","from keras.layers.core import Dense\n","from keras.layers import Flatten\n","from keras.layers import Input\n","import tensorflow as tf\n","\n","\n","import pandas as pd\n","import numpy as np\n","import os\n","from tensorflow import keras\n","from random import randrange\n","from IPython.display import YouTubeVideo\n","#import keras_metrics"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"a7kZdXoqMnwe","colab_type":"code","colab":{},"outputId":"32fa4ac7-1ddb-47f1-b7a4-fcf6db159897"},"source":["CNNModel(100, 5) #batch size, epochs"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","3109/3109 [==============================]3109/3109 [==============================] - 4s 1ms/step - loss: 0.5876 - acc: 0.7377\n","\n","Epoch 2/5\n","3109/3109 [==============================]3109/3109 [==============================] - 5s 2ms/step - loss: 0.4593 - acc: 0.7827\n","\n","Epoch 3/5\n","3109/3109 [==============================]3109/3109 [==============================] - 5s 2ms/step - loss: 0.3818 - acc: 0.8316\n","\n","Epoch 4/5\n","3109/3109 [==============================]3109/3109 [==============================] - 4s 1ms/step - loss: 0.3075 - acc: 0.8726\n","\n","Epoch 5/5\n","3109/3109 [==============================]3109/3109 [==============================] - 4s 1ms/step - loss: 0.2714 - acc: 0.8902\n","\n","2073/2073 [==============================]2073/2073 [==============================] - 1s 425us/step\n","\n","0.8845875545279507\n","\n","the order of the Real labels is [speech, animal, music, vehicle]\n","\n","0.) youtube id 5rks4FNDYPw has (a/an) music , Real label is [0. 0. 1. 0.]\n","1.) youtube id 0WYSS13Hqy8 has (a/an) human speaker , Real label is [0. 0. 1. 0.]\n","2.) youtube id hZYFGJ2Tr_g has (a/an) human speaker , Real label is [0. 0. 1. 0.]\n","3.) youtube id 3gFQwviPv9g has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","4.) youtube id MeAykJrFfJs has (a/an) human speaker , Real label is [0. 0. 1. 0.]\n","5.) youtube id Lfl2GhUJsoY has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","6.) youtube id 5G05PSrnr1o has (a/an) vehicle , Real label is [0. 0. 0. 1.]\n","7.) youtube id 5X6q35fYKLc has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","8.) youtube id Bg0gtKsMV6E has (a/an) vehicle , Real label is [0. 0. 0. 1.]\n","9.) youtube id CCPJa-FjWho has (a/an) human speaker , Real label is [0. 0. 1. 0.]\n","10.) youtube id PJf16pkFAuI has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","11.) youtube id lKS7fQ42Zn4 has (a/an) human speaker , Real label is [0. 0. 1. 0.]\n","12.) youtube id Y9kHCgC121c has (a/an) animal , Real label is [0. 1. 0. 0.]\n","13.) youtube id DiP_I4tqjqs has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","14.) youtube id gfQnUI-s6po has (a/an) vehicle , Real label is [0. 0. 0. 1.]\n","15.) youtube id g2W2pUy7O5k has (a/an) music , Real label is [0. 0. 1. 0.]\n","16.) youtube id EL8H2Q62v3o has (a/an) music , Real label is [0. 0. 1. 0.]\n","17.) youtube id I5lkr3d8yO8 has (a/an) vehicle , Real label is [1. 0. 0. 0.]\n","18.) youtube id TEuWnyMj3XQ has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","19.) youtube id lW2WOgt-P9U has (a/an) music , Real label is [0. 0. 1. 0.]\n","\n"," ========= \n"," youtube video to verify prediction no 17 (vehicle): \n","\n","\n"," to verify the prediction you can go to https://www.youtube.com/watch?v=I5lkr3d8yO8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"m9HZoXg4Mnwh","colab_type":"code","colab":{},"outputId":"4a24d19c-ec70-4afe-931a-4b905efd13f6"},"source":["ONNModel(20, 10) #batch size, epochs"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","=======================\n"," using 1280/10-100-1000 ONN\n","=================\n","\n","Epoch 1/10\n","3109/3109 [==============================]3109/3109 [==============================] - 1s 191us/step - loss: 0.4906 - acc: 0.7645\n","\n","Epoch 2/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 146us/step - loss: 0.3773 - acc: 0.8157\n","\n","Epoch 3/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 142us/step - loss: 0.3018 - acc: 0.8684\n","\n","Epoch 4/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 154us/step - loss: 0.2662 - acc: 0.8881\n","\n","Epoch 5/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 143us/step - loss: 0.2261 - acc: 0.9103\n","\n","Epoch 6/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 148us/step - loss: 0.2144 - acc: 0.9161\n","\n","Epoch 7/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 143us/step - loss: 0.1826 - acc: 0.9293\n","\n","Epoch 8/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 151us/step - loss: 0.1793 - acc: 0.9321\n","\n","Epoch 9/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 159us/step - loss: 0.1701 - acc: 0.9377\n","\n","Epoch 10/10\n","3109/3109 [==============================]3109/3109 [==============================] - 0s 146us/step - loss: 0.1671 - acc: 0.9372\n","\n","2073/2073 [==============================]2073/2073 [==============================] - 0s 54us/step\n","\n","0.8938736129485635\n","\n"," =========================using 1280/10-100-1000 ONN ========================== \n","\n","\n","the order of the Real labels is [speech, animal, music, vehicle]\n","\n","0.) youtube id 5rks4FNDYPw has (a/an) music , Real label is [0. 0. 1. 0.]\n","1.) youtube id 0WYSS13Hqy8 has (a/an) music , Real label is [0. 0. 1. 0.]\n","2.) youtube id hZYFGJ2Tr_g has (a/an) music , Real label is [0. 0. 1. 0.]\n","3.) youtube id 3gFQwviPv9g has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","4.) youtube id MeAykJrFfJs has (a/an) music , Real label is [0. 0. 1. 0.]\n","5.) youtube id Lfl2GhUJsoY has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","6.) youtube id 5G05PSrnr1o has (a/an) music , Real label is [0. 0. 0. 1.]\n","7.) youtube id 5X6q35fYKLc has (a/an) music , Real label is [1. 0. 0. 0.]\n","8.) youtube id Bg0gtKsMV6E has (a/an) music , Real label is [0. 0. 0. 1.]\n","9.) youtube id CCPJa-FjWho has (a/an) music , Real label is [0. 0. 1. 0.]\n","10.) youtube id PJf16pkFAuI has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","11.) youtube id lKS7fQ42Zn4 has (a/an) music , Real label is [0. 0. 1. 0.]\n","12.) youtube id Y9kHCgC121c has (a/an) human speaker , Real label is [0. 1. 0. 0.]\n","13.) youtube id DiP_I4tqjqs has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","14.) youtube id gfQnUI-s6po has (a/an) music , Real label is [0. 0. 0. 1.]\n","15.) youtube id g2W2pUy7O5k has (a/an) music , Real label is [0. 0. 1. 0.]\n","16.) youtube id EL8H2Q62v3o has (a/an) music , Real label is [0. 0. 1. 0.]\n","17.) youtube id I5lkr3d8yO8 has (a/an) human speaker , Real label is [1. 0. 0. 0.]\n","18.) youtube id TEuWnyMj3XQ has (a/an) music , Real label is [1. 0. 0. 0.]\n","19.) youtube id lW2WOgt-P9U has (a/an) music , Real label is [0. 0. 1. 0.]\n","\n"," ========= \n"," youtube video to verify prediction no 9 (music): \n","\n","\n"," to verify the prediction you can go to https://www.youtube.com/watch?v=CCPJa-FjWho\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AKPwCB9-Mnwl","colab_type":"code","colab":{},"outputId":"82067db3-fb50-40bb-80a9-155d4677a5e6"},"source":["multiCNN()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[INFO] compiling model...\n","Epoch 1/5\n","4059/4059 [==============================] - 9s 2ms/step - loss: 1.8260 - speech_output_loss: 0.4121 - animal_output_loss: 0.4281 - music_output_loss: 0.5217 - vehicle_output_loss: 0.4640 - speech_output_precision: 0.1989 - animal_output_precision: 0.1992 - music_output_precision: 0.1990 - vehicle_output_precision: 0.1991\n","Epoch 2/5\n","3584/4059 [=========================>....] - ETA: 1s - loss: 0.7950 - speech_output_loss: 0.1847 - animal_output_loss: 0.2081 - music_output_loss: 0.2186 - vehicle_output_loss: 0.1836 - speech_output_precision: 0.0638 - animal_output_precision: 0.0638 - music_output_precision: 0.0639 - vehicle_output_precision: 0.0637"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kGB_CV7wMnwp","colab_type":"code","colab":{}},"source":["multiONN()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AjDIS_x0Mnws","colab_type":"code","colab":{}},"source":["def forSpeech(data):    \n","    \n","    model=Conv2D(32, (3, 3), padding=\"same\")(data)\n","    #model=Conv2D(16, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(data)\n","    model=MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(model)\n","    \n","    model=Conv2D(32, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(model)\n","    model=MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(model)\n","    \n","    model=Conv2D(32, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(model)\n","    \n","    model=Flatten()(model)\n","    model=Dense(1000, activation='relu')(model)\n","    #model=Dense(1, activation='softmax', name=\"speech_output\")(model)\n","    model=Dense(2, activation='softmax', name=\"speech_output\")(model)\n","\n","    return model\n","\n","def forAnimal(data):\n","    \n","    model=Conv2D(16, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(data)\n","    model=MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(model)\n","    \n","    model=Conv2D(32, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(model)\n","    model=MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(model)\n","    \n","    model=Conv2D(32, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(model)\n","    \n","    model=Flatten()(model)\n","    model=Dense(1000, activation='relu')(model)\n","    #model=Dense(1, activation='softmax', name=\"animal_output\")(model)\n","    model=Dense(2, activation='softmax', name=\"animal_output\")(model)\n","    \n","\n","    \n","    return model\n","\n","def forMusic(data):\n","    \n","    model=Conv2D(16, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(data)\n","    model=MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(model)\n","    \n","    model=Conv2D(32, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(model)\n","    model=MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(model)\n","    \n","    model=Conv2D(32, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(model)\n","    \n","    model=Flatten()(model)\n","    model=Dense(1000, activation='relu')(model)\n","    #model=Dense(1, activation='softmax', name=\"music_output\")(model)   \n","    model=Dense(2, activation='softmax', name=\"music_output\")(model)   \n","    \n","    return model\n","\n","def forVehicle(data):\n","    \n","    model=Conv2D(16, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(data)\n","    model=MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(model)\n","    \n","    model=Conv2D(32, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(model)\n","    model=MaxPooling2D(pool_size=(2, 2), strides=(1, 1))(model)\n","    \n","    model=Conv2D(32, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1))(model)\n","    \n","    model=Flatten()(model)\n","    model=Dense(1000, activation='relu')(model)\n","    #model=Dense(1, activation='softmax', name=\"vehicle_output\")(model)    \n","    model=Dense(2, activation='softmax', name=\"vehicle_output\")(model)    \n","    \n","    return model\n","\n","def forSpeechONN(data):        \n","    \n","    model2 = Dense(10, activation='relu',input_shape=(1280,))(data)\n","    model2 = Dense(100, activation='relu')(model2)\n","    model2 = Dense(1000, activation='relu')(model2)\n","    #model2 = Dense(1, activation='softmax', name=\"speech_output2\")(model2)\n","    model2 = Dense(2, activation='softmax', name=\"speech_output2\")(model2)\n","\n","    return model2\n","\n","\n","def forAnimalONN(data):    \n","    \n","    model2 = Dense(10, activation='relu',input_shape=(1280,))(data)\n","    model2 = Dense(100, activation='relu')(model2)\n","    model2 = Dense(1000, activation='relu')(model2)\n","    #model2 = Dense(1, activation='softmax', name=\"animal_output2\")(model2)\n","    model2 = Dense(2, activation='softmax', name=\"animal_output2\")(model2)\n","\n","    return model2\n","\n","def forMusicONN(data):    \n","    \n","    model2 = Dense(10, activation='relu',input_shape=(1280,))(data)\n","    model2 = Dense(100, activation='relu')(model2)\n","    model2 = Dense(1000, activation='relu')(model2)\n","    #model2 = Dense(1, activation='softmax', name=\"music_output2\")(model2)\n","    model2 = Dense(2, activation='softmax', name=\"music_output2\")(model2)\n","\n","    return model2\n","\n","def forVehicleONN(data):    \n","    \n","    model2 = Dense(10, activation='relu',input_shape=(1280,))(data)\n","    model2 = Dense(100, activation='relu')(model2)\n","    model2 = Dense(1000, activation='relu')(model2)\n","    #model2 = Dense(1, activation='softmax', name=\"vehicle_output2\")(model2)\n","    model2 = Dense(2, activation='softmax', name=\"vehicle_output2\")(model2)\n","\n","    return model2\n","\n","def multiONN():\n","    X=np.load('XFullForMulti.npy')\n","    df=pd.read_csv('theLabels.csv')\n","    \n","    X2=X.reshape(len(X), 10*128)\n","\n","\n","    myInputONN=Input(shape=(10*128,))\n","\n","    spONN = forSpeechONN(myInputONN)\n","    anONN = forAnimalONN(myInputONN)\n","    muONN = forMusicONN(myInputONN)\n","    veONN = forVehicleONN(myInputONN)\n","\n","    # losses2 = {\n","    # \"speech_output2\": \"binary_crossentropy\",\n","    # \"animal_output2\": \"binary_crossentropy\",\n","    # \"music_output2\": \"binary_crossentropy\",\n","    # \"vehicle_output2\": \"binary_crossentropy\"\n","    # }\n","\n","    losses2 = {\n","    \"speech_output2\": \"sparse_categorical_crossentropy\",\n","    \"animal_output2\": \"sparse_categorical_crossentropy\",\n","    \"music_output2\": \"sparse_categorical_crossentropy\",\n","    \"vehicle_output2\": \"sparse_categorical_crossentropy\"\n","    }\n","\n","    theClassesONN = [spONN,anONN,muONN,veONN]\n","\n","    multiModelONN = Model(inputs=myInputONN, outputs=theClassesONN)\n","    print(\"[INFO] compiling model for ONN...\")\n","    multiModelONN.compile(optimizer='adam', loss=losses2, metrics=[keras_metrics.precision()])\n","    multiModelONN.fit(X2,{\"speech_output2\": df['Speech'], \"animal_output2\": df['Animal'], \"music_output2\": df['Music'], \"vehicle_output2\": df['Vehicle']}, epochs=5)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ghNWr8UQMnwv","colab_type":"code","colab":{}},"source":["def multiCNN():\n","    X=np.load('XFullForMulti.npy')\n","    df=pd.read_csv('theLabels.csv')\n","    \n","    myInput=Input(shape=(10,128,1))\n","\n","    sp = forSpeech(myInput)\n","    an = forAnimal(myInput)\n","    mu = forMusic(myInput)\n","    ve = forVehicle(myInput)\n","\n","    theClasses = [sp,an,mu,ve]\n","\n","    multiModel = Model(inputs=myInput, outputs=theClasses)\n","\n","    # losses = {\n","    # \"speech_output\": \"categorical_crossentropy\",\n","    # \"animal_output\": \"categorical_crossentropy\",\n","    # \"music_output\": \"categorical_crossentropy\",\n","    # \"vehicle_output\": \"categorical_crossentropy\"\n","    # }\n","\n","    # losses = {\n","    # \"speech_output\": \"binary_crossentropy\",\n","    # \"animal_output\": \"binary_crossentropy\",\n","    # \"music_output\": \"binary_crossentropy\",\n","    # \"vehicle_output\": \"binary_crossentropy\"\n","    # }\n","\n","    losses = {\n","    \"speech_output\": \"sparse_categorical_crossentropy\",\n","    \"animal_output\": \"sparse_categorical_crossentropy\",\n","    \"music_output\": \"sparse_categorical_crossentropy\",\n","    \"vehicle_output\": \"sparse_categorical_crossentropy\"\n","    }\n","\n","\n","    # initialize the optimizer and compile the model\n","    print(\"[INFO] compiling model...\")\n","    multiModel.compile(optimizer='adam', loss=losses, metrics=[keras_metrics.precision()])\n","    \n","    multiModel.fit(X,{\"speech_output\": df['Speech'], \"animal_output\": df['Animal'], \"music_output\": df['Music'], \"vehicle_output\": df['Vehicle']}, epochs=5)\n","    \n","def multiONN():\n","    X=np.load('XFullForMulti.npy')\n","    df=pd.read_csv('theLabels.csv')\n","    \n","    X2=X.reshape(len(X), 10*128)\n","\n","\n","    myInputONN=Input(shape=(10*128,))\n","\n","    spONN = forSpeechONN(myInputONN)\n","    anONN = forAnimalONN(myInputONN)\n","    muONN = forMusicONN(myInputONN)\n","    veONN = forVehicleONN(myInputONN)\n","\n","    # losses2 = {\n","    # \"speech_output2\": \"binary_crossentropy\",\n","    # \"animal_output2\": \"binary_crossentropy\",\n","    # \"music_output2\": \"binary_crossentropy\",\n","    # \"vehicle_output2\": \"binary_crossentropy\"\n","    # }\n","\n","    losses2 = {\n","    \"speech_output2\": \"sparse_categorical_crossentropy\",\n","    \"animal_output2\": \"sparse_categorical_crossentropy\",\n","    \"music_output2\": \"sparse_categorical_crossentropy\",\n","    \"vehicle_output2\": \"sparse_categorical_crossentropy\"\n","    }\n","\n","    theClassesONN = [spONN,anONN,muONN,veONN]\n","\n","    multiModelONN = Model(inputs=myInputONN, outputs=theClassesONN)\n","    print(\"[INFO] compiling model for ONN...\")\n","    multiModelONN.compile(optimizer='adam', loss=losses2, metrics=[keras_metrics.precision()])\n","    multiModelONN.fit(X2,{\"speech_output2\": df['Speech'], \"animal_output2\": df['Animal'], \"music_output2\": df['Music'], \"vehicle_output2\": df['Vehicle']}, epochs=5)\n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7myXuUSMMnwy","colab_type":"code","colab":{}},"source":["def CNNModel(b, e):\n","    \n","    xtr = np.load('XTrain.npy')\n","    ytr=np.load('YTrain.npy')\n","    xte=np.load('Xtest.npy')\n","    yte = np.load('Ytest.npy')\n","    ytidNew=np.load('ytidNew.npy')\n","    X=np.load('XFull.npy')\n","    dummy_y=np.load('encoded.npy')\n","    model = keras.Sequential()\n","\n","    model.add(keras.layers.Conv2D(16, kernel_size=(1, 6), strides=(2, 2), activation='relu',input_shape=(10,128,1)))\n","    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n","\n","    model.add(keras.layers.Conv2D(32, kernel_size=(1, 6), strides=(1, 1), activation='relu',padding=\"same\"))\n","    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n","\n","    model.add(keras.layers.Conv2D(32, kernel_size=(1, 6), strides=(1, 1), activation='relu',padding=\"same\"))\n","    #model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))# testing\n","\n","    model.add(keras.layers.Flatten())\n","    model.add(keras.layers.Dense(1000, activation='relu'))\n","    model.add(keras.layers.Dense(4, activation='softmax'))\n","    \n","    #model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","    ### \n","    #batch size 20 with 10 epochs was good\n","    model.fit(xtr, np.array(ytr), shuffle=True, batch_size=b, epochs=e)\n","\n","    test_loss, test_acc = model.evaluate(xte, np.array(yte))\n","    print(test_acc)\n","    \n","    # just predicting first 20 videos\n","    pred = model.predict(X[0:20])\n","    chosen = []\n","    ind=0\n","    for x in pred:\n","        if np.where(x == (max(x)))[0]==0:\n","            chosen.append('human speaker')\n","        if np.where(x == (max(x)))[0]==1:\n","            chosen.append('animal')\n","        if np.where(x == (max(x)))[0]==2:\n","            chosen.append('music')\n","        if np.where(x == (max(x)))[0]==3:\n","            chosen.append('vehicle')\n","\n","    #[human speaker, animal, music, vehicle]  \n","    print(\"\\nthe order of the Real labels is [speech, animal, music, vehicle]\\n\")\n","    for i in ytidNew[0:20]:    \n","        print('{0}.) youtube id {1} has (a/an) {2} , Real label is {3}'.format(ind, i, chosen[ind], dummy_y[ind]))\n","        ind+=1\n","\n","    r = randrange(0,20)\n","    #https://www.youtube.com/watch?v=\n","    print('\\n ========= \\n youtube video to verify prediction no {0} ({1}): \\n'.format(r, chosen[r]))\n","    print(\"\\n to verify the prediction you can go to https://www.youtube.com/watch?v={0}\".format(ytidNew[r]))\n","    YouTubeVideo(ytidNew[r]) # functionality imported from an IPython.display library\n","    \n","def ONNModel(b, e):\n","    \n","    xtr = np.load('XTrain.npy')\n","    ytr=np.load('YTrain.npy')\n","    xte=np.load('Xtest.npy')\n","    yte = np.load('Ytest.npy')\n","    ytidNew=np.load('ytidNew.npy')\n","    X=np.load('XFull.npy')\n","    dummy_y=np.load('encoded.npy')\n","    model2 = keras.Sequential()\n","    model2.add(keras.layers.Dense(10, activation='relu',input_shape=(1280,)))\n","    model2.add(keras.layers.Dense(100, activation='relu'))\n","    model2.add(keras.layers.Dense(1000, activation='relu'))\n","    model2.add(keras.layers.Dense(4, activation='softmax'))\n","\n","    model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    \n","    xtr2=xtr.reshape(len(xtr),10*128)\n","    xte2=xte.reshape(len(xte),10*128)\n","    print(\"\\n=======================\\n using 1280/10-100-1000 ONN\\n=================\\n\")\n","    model2.fit(xtr2, np.array(ytr), shuffle=True, batch_size=b, epochs=e)\n","\n","    test_loss, test_acc = model2.evaluate(xte2, np.array(yte))\n","    #test_loss, test_acc = model.evaluate(xte, multiLabelsNew[2000:])\n","    print(test_acc)\n","\n","    ###### just predicting first 20 videos\n","    pred = model2.predict(X[0:20].reshape(len(X[0:20]),10*128))\n","    chosen = []\n","    ind=0\n","    for x in pred:\n","        if np.where(x == (max(x)))[0]==0:\n","            chosen.append('human speaker')\n","        if np.where(x == (max(x)))[0]==1:\n","            chosen.append('animal')\n","        if np.where(x == (max(x)))[0]==2:\n","            chosen.append('music')\n","        if np.where(x == (max(x)))[0]==3:\n","            chosen.append('vehicle')\n","\n","    #[human speaker, animal, music, vehicle] \n","    print(\"\\n =========================using 1280/10-100-1000 ONN ========================== \\n\")\n","    print(\"\\nthe order of the Real labels is [speech, animal, music, vehicle]\\n\")\n","    for i in ytidNew[0:20]:    \n","        print('{0}.) youtube id {1} has (a/an) {2} , Real label is {3}'.format(ind, i, chosen[ind], dummy_y[ind]))\n","        ind+=1\n","\n","    r = randrange(0,20)\n","\n","    print('\\n ========= \\n youtube video to verify prediction no {0} ({1}): \\n'.format(r, chosen[r]))\n","    print(\"\\n to verify the prediction you can go to https://www.youtube.com/watch?v={0}\".format(ytidNew[r]))\n","    YouTubeVideo(ytidNew[r]) # functionality imported from an IPython.display library"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xYR-s-uKMnw1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}